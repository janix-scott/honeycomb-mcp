name: Honeycomb MCP Evaluation

on:
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      server_url:
        description: 'MCP Server URL'
        required: false
        default: 'http://localhost:3000'
      models:
        description: 'Models to use (JSON: {"provider":"model"})'
        required: false
        default: '{"openai":"gpt-4o","anthropic":"claude-3-sonnet"}'

permissions:
  contents: read
  pull-requests: write

jobs:
  run-evaluation:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup pnpm
      uses: pnpm/action-setup@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: 18
        cache: 'pnpm'
        
    - name: Install dependencies
      run: pnpm install
        
    - name: Build MCP server
      run: pnpm run build
        
    - name: Create MCP config
      run: |
        echo '${{ secrets.MCP_CONFIG }}' > .mcp-honeycomb.json
        echo "Created MCP config file"
        
    - name: Run evaluations
      run: |
        pnpm tsx eval/scripts/run-eval.ts run
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        MCP_SERVER_COMMAND: "node build/index.mjs"
        MCP_SERVER_URL: ${{ inputs.server_url || '' }}  # URL overrides command if provided
        EVAL_MODELS: ${{ inputs.models }}
        EVAL_CONCURRENCY: "2"
      
    - name: Upload evaluation results
      uses: actions/upload-artifact@v4
      with:
        name: evaluation-results
        path: |
          eval/results/*.json
          eval/reports/*.html
        
    - name: Parse and add evaluation summary
      if: success()
      run: |
        # Find the latest summary file
        SUMMARY_FILE=$(ls -t eval/results/summary-*.json | head -1 || echo "")
        
        if [ -z "$SUMMARY_FILE" ] || [ ! -f "$SUMMARY_FILE" ]; then
          echo "No summary file found. Evaluation may have failed."
          exit 0
        fi
        
        # Extract key metrics
        TOTAL=$(jq '.totalTests' $SUMMARY_FILE)
        PASSED=$(jq '.passed' $SUMMARY_FILE)
        FAILED=$(jq '.failed' $SUMMARY_FILE)
        SUCCESS_RATE=$(jq '.successRate * 100' $SUMMARY_FILE)
        
        # Add summary as job output
        echo "total=$TOTAL" >> $GITHUB_OUTPUT
        echo "passed=$PASSED" >> $GITHUB_OUTPUT
        echo "failed=$FAILED" >> $GITHUB_OUTPUT
        echo "success_rate=$SUCCESS_RATE" >> $GITHUB_OUTPUT
        
        # Add summary comment to PR
        if [ "${{ github.event_name }}" == "pull_request" ]; then
          PR_COMMENT="## Honeycomb MCP Evaluation Results\n\n"
          PR_COMMENT+="- Total Tests: $TOTAL\n"
          PR_COMMENT+="- Passed: $PASSED\n"
          PR_COMMENT+="- Failed: $FAILED\n"
          PR_COMMENT+="- Success Rate: ${SUCCESS_RATE}%\n\n"
          PR_COMMENT+="[View detailed results in the workflow artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})"
          
          echo -e "$PR_COMMENT" > pr_comment.txt
          
          gh pr comment ${{ github.event.pull_request.number }} --body-file pr_comment.txt
        fi
      env:
        GH_TOKEN: ${{ github.token }}